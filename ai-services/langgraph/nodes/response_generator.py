#!/usr/bin/env python3
"""
Nodo Generador de Respuestas para LangGraph

Genera respuestas finales para el usuario bas√°ndose en el contexto,
resultados RAG y acciones ejecutadas.

Autor: PATCO Development Team
Versi√≥n: 1.0.0
Fecha: Enero 2025
"""

from typing import Dict, Any

import google.generativeai as genai
import structlog

from schemas import ConversationState, ConversationMessage
from utils.logging_config import LoggingMixin
from utils.mcp_client import MCPClient
from config import settings

logger = structlog.get_logger(__name__)


class ResponseGeneratorNode(LoggingMixin):
    """Nodo para generaci√≥n de respuestas finales al usuario."""
    
    def __init__(self, mcp_client: MCPClient):
        """
        Inicializa el nodo generador de respuestas.
        
        Args:
            mcp_client: Cliente MCP para herramientas
        """
        self.mcp_client = mcp_client
        self._initialized = False
        
        # Configurar Gemini API
        if settings.GEMINI_API_KEY:
            genai.configure(api_key=settings.GEMINI_API_KEY)
            self.model = genai.GenerativeModel('gemini-1.5-flash')
        else:
            self.model = None
            self.logger.warning("‚ö†Ô∏è GEMINI_API_KEY no configurada")
    
    async def initialize(self) -> None:
        """Inicializa el nodo."""
        
        try:
            self.log_method_call("initialize")
            
            # Verificar configuraci√≥n
            if not self.model:
                self.logger.warning("‚ö†Ô∏è Modelo Gemini no disponible para generaci√≥n")
            
            self._initialized = True
            self.log_method_result("initialize")
            
        except Exception as e:
            self.log_error("initialize", e)
            raise
    
    async def process(self, state: ConversationState) -> ConversationState:
        """
        Genera respuesta final para el usuario.
        
        Args:
            state: Estado actual de la conversaci√≥n
            
        Returns:
            Estado actualizado con respuesta final
        """
        
        try:
            self.log_method_call(
                "process",
                intent=state.current_intent,
                has_rag_results=bool(state.rag_results),
                actions_count=len(state.actions)
            )
            
            # Si ya hay una respuesta (ej. desde RAG), verificar si necesita mejora
            if state.response and not self._needs_enhancement(state):
                self.logger.debug("‚úÖ Respuesta existente es suficiente")
                return state
            
            # Generar respuesta seg√∫n el contexto
            response = await self._generate_contextual_response(state)
            
            # Actualizar estado
            state.response = response
            
            # Agregar metadatos de procesamiento
            state.processing_metadata.update({
                "response_generator": {
                    "response_length": len(response) if response else 0,
                    "generation_method": self._get_generation_method(state),
                    "enhanced_existing": bool(state.response and self._needs_enhancement(state))
                }
            })
            
            self.log_method_result(
                "process",
                response_length=len(response) if response else 0
            )
            
            return state
            
        except Exception as e:
            self.log_error("process", e)
            state.error_message = f"Error generando respuesta: {str(e)}"
            state.response = "Lo siento, tuve un problema generando la respuesta. ¬øPuedes intentar de nuevo?"
            return state
    
    def _needs_enhancement(self, state: ConversationState) -> bool:
        """
        Determina si una respuesta existente necesita mejora.
        
        Args:
            state: Estado de la conversaci√≥n
            
        Returns:
            True si necesita mejora
        """
        
        if not state.response:
            return True
        
        # Si hay acciones ejecutadas, agregar informaci√≥n sobre ellas
        if state.actions:
            return True
        
        # Si la respuesta es muy corta y hay contexto adicional
        if len(state.response) < 50 and (state.context or state.rag_results):
            return True
        
        return False
    
    def _get_generation_method(self, state: ConversationState) -> str:
        """Determina el m√©todo de generaci√≥n usado."""
        
        if state.rag_results:
            return "rag_enhanced"
        elif state.actions:
            return "action_based"
        elif state.current_intent == "greeting":
            return "greeting"
        elif state.current_intent == "confirmation":
            return "confirmation"
        else:
            return "contextual"
    
    async def _generate_contextual_response(self, state: ConversationState) -> str:
        """
        Genera respuesta contextual basada en el estado.
        
        Args:
            state: Estado de la conversaci√≥n
            
        Returns:
            Respuesta generada
        """
        
        try:
            # Determinar tipo de respuesta seg√∫n intenci√≥n
            if state.current_intent == "greeting":
                return self._generate_greeting_response(state)
            
            elif state.current_intent == "confirmation":
                return self._generate_confirmation_response(state)
            
            elif state.actions:
                return await self._generate_action_response(state)
            
            elif state.rag_results:
                # Si ya hay respuesta RAG, mejorarla si es necesario
                if state.response:
                    return await self._enhance_rag_response(state)
                else:
                    return "Encontr√© informaci√≥n relevante, pero hubo un problema proces√°ndola."
            
            else:
                return await self._generate_general_response(state)
                
        except Exception as e:
            self.log_error("_generate_contextual_response", e)
            return "Lo siento, tuve un problema generando la respuesta."
    
    def _generate_greeting_response(self, state: ConversationState) -> str:
        """Genera respuesta de saludo."""
        
        context = state.context
        
        # Informaci√≥n b√°sica del servicio
        service_info = []
        if context.fsm_order_id:
            service_info.append(f"üìã Orden de servicio: {context.fsm_order_id}")
        
        if context.equipment_ids:
            equipment_count = len(context.equipment_ids)
            service_info.append(f"üîß Equipos asignados: {equipment_count} equipo{'s' if equipment_count > 1 else ''}")
        
        if context.location:
            service_info.append(f"üìç Ubicaci√≥n: {context.location}")
        
        # Construir respuesta
        response_parts = [
            "¬°Hola! üëã Soy tu asistente IA para el servicio t√©cnico.",
            ""
        ]
        
        if service_info:
            response_parts.append("**Informaci√≥n del servicio:**")
            response_parts.extend(service_info)
            response_parts.append("")
        
        response_parts.extend([
            "Estoy aqu√≠ para ayudarte durante todo el proceso:",
            "‚Ä¢ Responder preguntas t√©cnicas",
            "‚Ä¢ Buscar informaci√≥n en manuales y procedimientos", 
            "‚Ä¢ Ayudarte con checklists y verificaciones",
            "‚Ä¢ Registrar el progreso del trabajo",
            "",
            "¬øHas llegado al sitio y est√°s listo para comenzar? üöÄ"
        ])
        
        return "\n".join(response_parts)
    
    def _generate_confirmation_response(self, state: ConversationState) -> str:
        """Genera respuesta de confirmaci√≥n."""
        
        last_message = state.messages[-1] if state.messages else None
        if not last_message:
            return "Entendido. ¬øEn qu√© m√°s puedo ayudarte?"
        
        message_lower = last_message.content.lower()
        
        # Respuestas seg√∫n el tipo de confirmaci√≥n
        if any(word in message_lower for word in ["s√≠", "si", "yes", "ok", "correcto"]):
            return "Perfecto. ¬øCu√°l es el siguiente paso?"
        
        elif any(word in message_lower for word in ["no", "nope", "incorrecto"]):
            return "Entendido. ¬øPuedes explicarme qu√© necesitas corregir o cambiar?"
        
        else:
            return "Entendido. ¬øHay algo m√°s en lo que pueda ayudarte?"
    
    async def _generate_action_response(self, state: ConversationState) -> str:
        """Genera respuesta basada en acciones ejecutadas."""
        
        if not state.actions:
            return "No hay acciones pendientes. ¬øEn qu√© m√°s puedo ayudarte?"
        
        # Agrupar acciones por tipo
        action_groups = {}
        for action in state.actions:
            action_type = action.action_type
            if action_type not in action_groups:
                action_groups[action_type] = []
            action_groups[action_type].append(action)
        
        response_parts = ["He procesado las siguientes acciones:", ""]
        
        # Describir acciones ejecutadas
        for action_type, actions in action_groups.items():
            if action_type == "update_fsm_order":
                response_parts.append("‚úÖ **Orden FSM actualizada**")
                for action in actions:
                    if "stage" in action.parameters:
                        response_parts.append(f"   ‚Ä¢ Estado cambiado a: {action.parameters['stage']}")
                    if "notes" in action.parameters:
                        response_parts.append(f"   ‚Ä¢ Notas agregadas")
            
            elif action_type == "create_checklist":
                response_parts.append("üìã **Checklist creado**")
                response_parts.append("   ‚Ä¢ Lista de verificaci√≥n lista para usar")
            
            elif action_type == "generate_report":
                response_parts.append("üìÑ **Reporte generado**")
                response_parts.append("   ‚Ä¢ Documento t√©cnico creado autom√°ticamente")
            
            else:
                response_parts.append(f"‚úÖ **{action_type.replace('_', ' ').title()}**")
        
        response_parts.extend([
            "",
            "¬øNecesitas realizar alguna otra acci√≥n o tienes alguna pregunta?"
        ])
        
        return "\n".join(response_parts)
    
    async def _enhance_rag_response(self, state: ConversationState) -> str:
        """Mejora una respuesta RAG existente."""
        
        if not self.model:
            return state.response  # Retornar respuesta original si no hay Gemini
        
        try:
            # Informaci√≥n adicional del contexto
            context_info = []
            if state.actions:
                context_info.append(f"Acciones ejecutadas: {len(state.actions)}")
            
            if state.entities.equipment_mentioned:
                context_info.append(f"Equipo mencionado: {state.entities.equipment_mentioned}")
            
            # Prompt para mejorar respuesta
            enhancement_prompt = f"""
            Mejora la siguiente respuesta t√©cnica agregando informaci√≥n contextual √∫til.
            
            Respuesta original:
            {state.response}
            
            Contexto adicional:
            {'; '.join(context_info) if context_info else 'Ninguno'}
            
            Instrucciones:
            - Mant√©n el contenido t√©cnico original
            - Agrega informaci√≥n contextual relevante al final
            - Usa un tono profesional pero amigable
            - Incluye una pregunta de seguimiento apropiada
            - Mant√©n la respuesta concisa
            
            Respuesta mejorada:
            """
            
            response = self.model.generate_content(enhancement_prompt)
            return response.text
            
        except Exception as e:
            self.log_error("_enhance_rag_response", e)
            return state.response  # Retornar original en caso de error
    
    async def _generate_general_response(self, state: ConversationState) -> str:
        """Genera respuesta general cuando no hay contexto espec√≠fico."""
        
        last_message = state.messages[-1] if state.messages else None
        if not last_message:
            return "¬øEn qu√© puedo ayudarte?"
        
        # Respuestas seg√∫n entidades detectadas
        if state.entities.equipment_mentioned:
            return f"""
            Veo que mencionas {state.entities.equipment_mentioned}. 
            
            Puedo ayudarte con:
            ‚Ä¢ Informaci√≥n t√©cnica y especificaciones
            ‚Ä¢ Procedimientos de mantenimiento
            ‚Ä¢ Soluci√≥n de problemas comunes
            ‚Ä¢ Checklists de verificaci√≥n
            
            ¬øQu√© necesitas saber espec√≠ficamente?
            """.strip()
        
        elif state.entities.problems:
            problems = ", ".join(state.entities.problems)
            return f"""
            Entiendo que hay problemas con: {problems}
            
            Para ayudarte mejor, necesito m√°s informaci√≥n:
            ‚Ä¢ ¬øQu√© equipo est√° presentando el problema?
            ‚Ä¢ ¬øCu√°ndo comenz√≥ el problema?
            ‚Ä¢ ¬øHas notado alg√∫n patr√≥n o s√≠ntoma espec√≠fico?
            
            Con estos detalles podr√© buscar la soluci√≥n m√°s apropiada.
            """.strip()
        
        elif state.entities.action:
            action = state.entities.action
            return f"""
            Entiendo que quieres {action}. 
            
            ¬øPuedes ser m√°s espec√≠fico sobre:
            ‚Ä¢ ¬øQu√© equipo o componente?
            ‚Ä¢ ¬øNecesitas un procedimiento espec√≠fico?
            ‚Ä¢ ¬øHay alg√∫n problema particular?
            
            As√≠ podr√© darte la informaci√≥n m√°s precisa.
            """.strip()
        
        else:
            return """
            Estoy aqu√≠ para ayudarte con el servicio t√©cnico.
            
            Puedo asistirte con:
            ‚Ä¢ Preguntas t√©cnicas sobre equipos
            ‚Ä¢ B√∫squeda de manuales y procedimientos
            ‚Ä¢ Soluci√≥n de problemas
            ‚Ä¢ Registro de actividades y progreso
            
            ¬øQu√© necesitas?
            """.strip()
    
    async def get_metrics(self) -> Dict[str, Any]:
        """Obtiene m√©tricas del nodo."""
        
        return {
            "initialized": self._initialized,
            "gemini_available": self.model is not None
        }